for(i in 1:(n-1)**2){
A[i,i] = 4
if((i%%(n-1))!=0){
A[i,i+1] = -1
A[i+1,i] = -1
}
if(i<=(n-1)*(n-2)){
A[i,i+(n-1)] = -1
A[i+(n-1),i] = -1
}
}
B = vector(length = (n-1)**2)
for(i in 1:(n-1)){
for(j in 1:(n-1)){
B[i+(n-1)*(j-1)] = (pi/n)**2*2*sin(i*pi/n)*cos(j*pi/n)
}
}
jacobi_result = as.vector(lsolve.jacobi(A,B)$x)
n <- 128
Nx <- n
Ny <- n
xgrid <- setup.grid.1D(x.up = 0, x.down = pi, N = Nx)
ygrid <- setup.grid.1D(x.up = 0, x.down = pi, N = Ny)
if(!require("ReacTran")){
install.packages("ReacTran")
library("ReacTran")
}
n <- 128
Nx <- n
Ny <- n
xgrid <- setup.grid.1D(x.up = 0, x.down = pi, N = Nx)
ygrid <- setup.grid.1D(x.up = 0, x.down = pi, N = Ny)
x <- xgrid$x.mid
y <- ygrid$x.mid
ygrid
x <- xgrid$x.mid
y <- ygrid$x.mid
T3 <- spMatrix(3,4, i=c(1,3:1), j=c(2,4:2), x=1:4)
T3 # only 3 non-zero entries, 5 = 1+4 !
showClass("TsparseMatrix")
## or just the subclasses' names
names(getClass("TsparseMatrix")@subclasses)
T3 <- spMatrix(3,4, i=c(1,3:1), j=c(2,4:2), x=1:4)
i <- c(1,3:8); j <- c(2,9,6:10); x <- 7 * (1:7)
(A <- sparseMatrix(i, j, x = x))                    ##  8 x 10 "dgCMatrix"
library("Matrix")
i <- c(1,3:8); j <- c(2,9,6:10); x <- 7 * (1:7)
(A <- sparseMatrix(i, j, x = x))                    ##  8 x 10 "dgCMatrix"
# 1-(3) other library n = 128
n = 5
A = matrix(0, nrow = n-1, ncol = n-1)
for(i in 1:(n-1)){
A[i,i] = 2
if(i < n-1){
A[i,i+1] = -1
A[i+1,i] = -1
}
}
A = as.sparseMatrix(A)
A <- as(A, "sparseMatrix")
A
# 1-(3) other library n = 128
n = 128
A = matrix(0, nrow = n-1, ncol = n-1)
for(i in 1:(n-1)){
A[i,i] = 2
if(i < n-1){
A[i,i+1] = -1
A[i+1,i] = -1
}
}
A <- as(A, "sparseMatrix")
A
x = (1:(n-1))*pi/n
B = (pi/n)**2*sin(x)
jacobi_result = as.vector(lsolve.jacobi(A,B, reltol = 1e-05, maxiter = 1e05)$x)
plot(x,jacobi_result)
n = 128
A = matrix(0, nrow = (n-1)**2, ncol = (n-1)**2)
for(i in 1:(n-1)**2){
A[i,i] = 4
if((i%%(n-1))!=0){
A[i,i+1] = -1
A[i+1,i] = -1
}
if(i<=(n-1)*(n-2)){
A[i,i+(n-1)] = -1
A[i+(n-1),i] = -1
}
}
A <- as(A, "sparseMatrix")
B = vector(length = (n-1)**2)
for(i in 1:(n-1)){
for(j in 1:(n-1)){
B[i+(n-1)*(j-1)] = (pi/n)**2*2*sin(i*pi/n)*cos(j*pi/n)
}
}
jacobi_result = as.vector(lsolve.jacobi(A,B)$x)
jacobi_result
u = matrix(ncol = n-1, nrow = n-1)
for(i in 1:(n-1)){
for(j in 1:(n-1)){
u[j,i] = jacobi_result[i+(n-1)*(j-1)]
}
}
if(!require("plotly")){
install.packages("plotly")
library("plotly")
}
grid = (1:(n-1))*pi/n
plot_ly(x = grid, y = grid, z = u) %>% add_surface()
n = 64
A = matrix(0, nrow = n-1, ncol = n-1)
for(i in 1:(n-1)){
A[i,i] = 2
if(i < n-1){
A[i,i+1] = -1
A[i+1,i] = -1
}
}
A <- as(A, "sparseMatrix")
x = (1:(n-1))*pi/n
B = (pi/n)**2*sin(x)
jacobi_result = as.vector(lsolve.jacobi(A,B)$x)
jacobi_result
plot(x,jacobi_result)
# 1-(3) other library n = 128
n = 128
A = matrix(0, nrow = n-1, ncol = n-1)
for(i in 1:(n-1)){
A[i,i] = 2
if(i < n-1){
A[i,i+1] = -1
A[i+1,i] = -1
}
}
A <- as(A, "sparseMatrix")
x = (1:(n-1))*pi/n
B = (pi/n)**2*sin(x)
jacobi_result = as.vector(lsolve.jacobi(A,B, reltol = 1e-05, maxiter = 1e05)$x)
jacobi_result
plot(x,jacobi_result)
f <- function(x) 1/(1-5*exp(-(0+1i)*x))
x <- seq(0, 2*pi, by=0.1)
plot(f(x))
z = complex(real = seq(0, pi, by=0.01),imaginary = seq(0,10,0.01))
z
plot(z)
z = complex(real = rep(xlim, length(ylim)),
imaginary = rep(ylim, each = length(xlim))))
z = complex(real = rep(xlim, length(ylim)),
imaginary = rep(ylim, each = length(xlim)))
xlim = seq(0, pi, by=0.01)
ylim = seq(0,10,0.01)
z = complex(real = rep(xlim, length(ylim)),
imaginary = rep(ylim, each = length(xlim)))
z
plot(z)
f <- function(z) z^2*(z-pi)^2
plot(f(z))
f <- function(z) cos(z)
plot(f(z))
ylim = seq(0,50,0.1)
z = complex(real = rep(xlim, length(ylim)),
imaginary = rep(ylim, each = length(xlim)))
plot(f(z))
plot(z)
ph <- "Statement of Purpose
Enthralled by mathematics, I sometimes hoped to spend my life studying it in a secluded cabin middle of the forest. As I got older, I became interested in contemplating reality rather than pure mathematics itself by the influence of my parents who actively participated in social movements. Naturally, I decided to major in statistics tackling practical problems yet maintaining the beauty of mathematics. My academic objectives become to contrive or develop statistical analysis methods for real phenomena and thus become a scholar who contributes to the world. However, as I delved deeply into statistics, I began to realize it is not enough to consider unpredictable and incomprehensible actualities through undergraduate studies. Thus I am applying to the statistics Ph.D. program at the [School].
First and foremost, I believe independent researchers in the field of statistics should be equipped with a strong theoretical background and intuition, and this belief led me to minor in mathematics. Taking algebra courses provided me a set of tools for dealing with multi-dimensional data, and I was able to obtain a concrete understanding of measure theory through a real analysis course. Not only this, I have tried to study beyond the undergraduate level. Through a graduate course named theory of statistics instructed by Prof. Byeong U. Park, I learned advanced theories including duality between hypothesis and CI, optimality of estimators, and statistical decision framework. The last one was especially intriguing because optimal decisions in the real world can be made by minimizing risk, and this framework is very close to my academic goal. Even though I was an undergraduate, with a strong mathematical background, I took second place in the final exam.
Once my perspective on probability changed completely after taking real analysis and theory of statistics, I hoped to study advanced probability theory rigorously, and finally I studied it independently with the book Probability and Measure by Patrick Billingsley. I grasped statistical concepts and proved related theorems that I had already learned in undergraduate courses such as conditional probability, central limit theorem, random process, and Markov chain based on measure theory. Moreover, as I became interested in the measure theory, I further studied the properties of Gaussian measure in undergraduate research program under Prof. Chaeyoung Lim. She taught me two Gaussian measures defined on same probability space are either equivalent or orthogonal, but not mixed-up. I comprehended when it comes to the random field, with the particular autocorrelation setting, two Gaussian measures are not identifiable. It was inciting to learn the advanced properties of probability measures, and a series of these studies deepened my interest in mathematics again. Through these experiences, I could prepare the fundamental and essential ground for further research in the future.
The application of statistics is as important as its theory, and thus I have joined Prof. Taesung Park’s laboratory to see how statistics can be applied to real life. My first research was making a diabetes prediction model using clinical and metabolite data. From this, I learned various statistical topics such as cross-validation, variable selection, study design, and survival analysis. After conducting this research, I am now participating in a national project, “Bio-Synergy,” researching the effectiveness of recommended food scores (RFS) in diabetes survival time. I extend the study by using genomic data to determine whether RFS affects incidences of diabetes in the gene-set level mechanisms by utilizing such tools as R, Python, and Plink to handle massive genomic data. I became proficient at pathway analysis in genomics and was amazed by how a statistical concept, p-value, demonstrates genetic mechanisms. Currently, I am absorbed in a multilevel linear regression model that reasonably explains biologically structured data such as proteomic peptide-level data. Adding 2-norm penalties to each level, shrunken and robust least square estimators can be found, and now I focus on statistical inference and limiting properties of these estimators. Based on Fan and Li’s article Variable Selection via Nonconcave Penalized Likelihood and its Oracle Properties, verifying asymptotic normality of estimator is the eventual aim of this research.
Most importantly, from this research experience I understood how fulfilling the methodological study process carried out by me was. Also, I improved my research techniques such as time management, searching references and abstracting main ideas from them, collaborating with colleagues, and working with diverse computing tools. Although I learned a lot of basic concepts and procedures of statistical research from my undergraduate courses, I realized that the attributes, expertise, and knowledge needed for research are different from what I have studied. In addition, through the study of Gaussian measure and limiting property of penalized estimators, I found that a more advanced theoretical background is needed to conduct professional research, and therefore, I am pursuing a Ph.D. to hone my skills.
Since there are many sub-disciplines of statistics that I have not encountered yet, I do not wish to restrict my interest to one specific area. As a part of this, I am taking a graduate deep learning course, and working on a project about knowledge distillation (KD) because I was inspired by the notion that knowledge of a large network can be transferred to a small one. I devised an increasing sequence of student networks that knowledge of the preceding one transmits to the next one, and I used Python and PyTorch to implement this and attempted to justify it through statistical learning theory. From the course, I discerned that a firm statistical basis can benefit modern machine learning, and I began looking forward to studying statistical learning that would be widely helpful.
Through undergraduate studies, I have been inspired by original thoughts of the past, and now I desire to proceed to pioneer new fields in statistics. I hope to dedicate myself to be a professor after PhD, devoting to society with professional advice on social issues. I feel more ready than ever to delve deeper into the field of statistics, and I am confident that [School] will afford an extraordinary environment for advanced studies leading me to be an incisive researcher, together with renowned faculty members and exceptional students from all over the world.
"
words <- split(ph, sep = " ")
words <- strsplit(ph, sep = " ")
words <- strsplit(ph, " ")
words
table(words)
result <- as.dataframe(table(words))
tab
result <- as.data.frame(table(words))
result
words <- strsplit(ph)
words <- strsplit(ph,"")
words
words <- strsplit(ph,"")
words %in% c(",",".","\n")
words <- strsplit(ph,"")[[1]]
words
words %in% c(",",".","\n")
words2 <- words[words %in% c(",",".","\n")]
result <- as.data.frame(table(words2))
result
words2 <- words[!words %in% c(",",".","\n")]
result <- as.data.frame(table(words2))
result
newph = paste0(words2)
newph
newph = paste0(words2, collapse = '')
newph
words3 <- strsplit(newph,"")[[1]]
result <- as.data.frame(table(words3))
result
words <- strsplit(ph,"")[[1]]
words2 <- words[!words %in% c(",",".","\n","(",")","[","]")]
newph = paste0(words2, collapse = '')
words3 <- strsplit(newph," ")[[1]]
result <- as.data.frame(table(words3))
result
getwd()
words_freq_analysis <- function(ph){
words <- strsplit(ph,"")[[1]]
words2 <- words[!words %in% c(",",".","\n","(",")","[","]")]
newph = paste0(words2, collapse = '')
words3 <- strsplit(newph," ")[[1]]
result <- as.data.frame(table(words3))
write.csv(result, "words freq analysis")
return 0
}
.s
ph <- "Statement of Purpose
Enthralled by mathematics, I sometimes hoped to spend my life studying it in a secluded cabin middle of the forest. As I got older, I became interested in contemplating reality rather than pure mathematics itself by the influence of my parents who actively participated in social movements. Naturally, I decided to major in statistics tackling practical problems yet maintaining the beauty of mathematics. My academic objectives become to contrive or develop statistical analysis methods for real phenomena and thus become a scholar who contributes to the world. However, as I delved deeply into statistics, I began to realize it is not enough to consider unpredictable and incomprehensible actualities through undergraduate studies. Thus I am applying to the statistics Ph.D. program at the [School].
First and foremost, I believe independent researchers in the field of statistics should be equipped with a strong theoretical background and intuition, and this belief led me to minor in mathematics. Taking algebra courses provided me a set of tools for dealing with multi-dimensional data, and I was able to obtain a concrete understanding of measure theory through a real analysis course. Not only this, I have tried to study beyond the undergraduate level. Through a graduate course named theory of statistics instructed by Prof. Byeong U. Park, I learned advanced theories including duality between hypothesis and CI, optimality of estimators, and statistical decision framework. The last one was especially intriguing because optimal decisions in the real world can be made by minimizing risk, and this framework is very close to my academic goal. Even though I was an undergraduate, with a strong mathematical background, I took second place in the final exam.
Once my perspective on probability changed completely after taking real analysis and theory of statistics, I hoped to study advanced probability theory rigorously, and finally I studied it independently with the book Probability and Measure by Patrick Billingsley. I grasped statistical concepts and proved related theorems that I had already learned in undergraduate courses such as conditional probability, central limit theorem, random process, and Markov chain based on measure theory. Moreover, as I became interested in the measure theory, I further studied the properties of Gaussian measure in undergraduate research program under Prof. Chaeyoung Lim. She taught me two Gaussian measures defined on same probability space are either equivalent or orthogonal, but not mixed-up. I comprehended when it comes to the random field, with the particular autocorrelation setting, two Gaussian measures are not identifiable. It was inciting to learn the advanced properties of probability measures, and a series of these studies deepened my interest in mathematics again. Through these experiences, I could prepare the fundamental and essential ground for further research in the future.
The application of statistics is as important as its theory, and thus I have joined Prof. Taesung Park’s laboratory to see how statistics can be applied to real life. My first research was making a diabetes prediction model using clinical and metabolite data. From this, I learned various statistical topics such as cross-validation, variable selection, study design, and survival analysis. After conducting this research, I am now participating in a national project, “Bio-Synergy,” researching the effectiveness of recommended food scores (RFS) in diabetes survival time. I extend the study by using genomic data to determine whether RFS affects incidences of diabetes in the gene-set level mechanisms by utilizing such tools as R, Python, and Plink to handle massive genomic data. I became proficient at pathway analysis in genomics and was amazed by how a statistical concept, p-value, demonstrates genetic mechanisms. Currently, I am absorbed in a multilevel linear regression model that reasonably explains biologically structured data such as proteomic peptide-level data. Adding 2-norm penalties to each level, shrunken and robust least square estimators can be found, and now I focus on statistical inference and limiting properties of these estimators. Based on Fan and Li’s article Variable Selection via Nonconcave Penalized Likelihood and its Oracle Properties, verifying asymptotic normality of estimator is the eventual aim of this research.
Most importantly, from this research experience I understood how fulfilling the methodological study process carried out by me was. Also, I improved my research techniques such as time management, searching references and abstracting main ideas from them, collaborating with colleagues, and working with diverse computing tools. Although I learned a lot of basic concepts and procedures of statistical research from my undergraduate courses, I realized that the attributes, expertise, and knowledge needed for research are different from what I have studied. In addition, through the study of Gaussian measure and limiting property of penalized estimators, I found that a more advanced theoretical background is needed to conduct professional research, and therefore, I am pursuing a Ph.D. to hone my skills.
Since there are many sub-disciplines of statistics that I have not encountered yet, I do not wish to restrict my interest to one specific area. As a part of this, I am taking a graduate deep learning course, and working on a project about knowledge distillation (KD) because I was inspired by the notion that knowledge of a large network can be transferred to a small one. I devised an increasing sequence of student networks that knowledge of the preceding one transmits to the next one, and I used Python and PyTorch to implement this and attempted to justify it through statistical learning theory. From the course, I discerned that a firm statistical basis can benefit modern machine learning, and I began looking forward to studying statistical learning that would be widely helpful.
Through undergraduate studies, I have been inspired by original thoughts of the past, and now I desire to proceed to pioneer new fields in statistics. I hope to dedicate myself to be a professor after PhD, devoting to society with professional advice on social issues. I feel more ready than ever to delve deeper into the field of statistics, and I am confident that [School] will afford an extraordinary environment for advanced studies leading me to be an incisive researcher, together with renowned faculty members and exceptional students from all over the world.
"
words_freq_analysis <- function(ph){
words <- strsplit(ph,"")[[1]]
words2 <- words[!words %in% c(",",".","\n","(",")","[","]")]
newph = paste0(words2, collapse = '')
words3 <- strsplit(newph," ")[[1]]
result <- as.data.frame(table(words3))
write.csv(result, "words freq analysis")
return(0)
}
words_freq_analysis(ph)
words_freq_analysis <- function(ph){
words <- strsplit(ph,"")[[1]]
words2 <- words[!words %in% c(",",".","\n","(",")","[","]")]
newph = paste0(words2, collapse = '')
words3 <- strsplit(newph," ")[[1]]
result <- as.data.frame(table(words3))
write.csv(result, "words freq analysis.csv")
return(0)
}
words_freq_analysis(ph)
ph <- "“We make a living by what we get, but we make a life by what we give.” This famous quote from Winston Churchill is what my parents always told me since I was young. They disciplined me that whatever I got was from the dedication of community members, so I should appreciate it and always keep in mind how to repay it. Following the conviction to contribute to society, I volunteered at the local nursing home and taught mathematics to impoverished children during my science high school years. Through volunteering, I became aware of real problems that deny natural rights and boundless possibilities of people. Concern about actual problems matters more than cultivating knowledge, and this enlightenment, as well as my interest in mathematics, became the decisive reason that led me to major in statistics, a discipline that deals with reality while maintaining the beauty of mathematics.
Based on academic distinctions at university, I had an opportunity to join an honor society named GLEAP, which I loved the motto of it; “Benefit the world corresponding to the academic excellence.” Working as a general executive director of GLEAP, I planned tutoring programs for underprivileged high school students related to elementary statistics. At first, students were indifferent to programs. I soon understood their uncooperative attitude came from their illness of mind caused by hardships of life, and I had time playing with them and talking about their difficulties in life instead of programs. As I showed severe concern about their life, students began to open their minds and finally actively participated in programs enjoying the pure pleasure of learning. Through this fulfilling experience, I could understand the worth of helping others and the pleasure of seeing them change their lives better. Also, through academic exchange with Singapore university students, I realized that despite various backgrounds, we all have the same enthusiasm to study and wonder how to dedicate to the world in our ways. GLEAP enabled me to reinforce my belief to devote to society with my knowledge and to understand there are a lot of excellent scholars in the world, and there is no reason to restrict myself only in my nation.
A turning point in my life came when I was in the army. One day, one of my comrades suddenly collapsed and hyperventilated with an unknown cause. While taking care of him about one month, my thought was like, “Why doctors cannot find the cause of his disease and provide appropriate medications?” Seeing his face drawn with unexplained pain, I wanted to find a way of aiding people who suffer from diseases of unknown etiology. Although I am not a physician, what if I provide statistical backgrounds for suitable medical service? I thoroughly felt the importance of biostatistics that can back up the dream of personalized medicine. After discharge from the military, I noticed that there is a biostatistics laboratory in the university, so I joined the laboratory to get to know what the biostatistics is and how this field of study can benefit the world.
Up to my undergraduate years, my life was experiencing new fields of study and appreciating the great joy of learning. From now on, I desire to contribute to a society based on my studies. Research experience in the biostatistics lab was an engaging experience, and I soon became eager to study more about it in the topmost research environment with prominent faculty and colleagues. That is why I am applying for the Ph.D. program in biostatistics in [School]. Should there are any obstacles while earning a Ph.D., I will always recall my belief to dedicate to the world.
"
words_freq_analysis(ph)
words_freq_analysis <- function(ph){
words <- strsplit(ph,"")[[1]]
words2 <- words[!words %in% c(",",".","\n","(",")","[","]","\"")]
newph = paste0(words2, collapse = '')
words3 <- strsplit(newph," ")[[1]]
result <- as.data.frame(table(words3))
write.csv(result, "words freq analysis.csv")
return(0)
}
words_freq_analysis(ph)
ph <- "    “We make a living by what we get, but we make a life by what we give.” This famous quote from Winston Churchill is what my parents always told me since I was young. They disciplined me that whatever I got was from the dedication of community members, so I should appreciate it and consistently keep in mind how to repay it. Following the conviction to contribute to society, I volunteered at the local nursing home and taught mathematics to impoverished children during my science high school years. Through volunteering, I became aware of real problems that deny natural rights and boundless possibilities of people. Concern about actual problems matters more than cultivating knowledge, and this enlightenment, as well as my interest in mathematics, became the decisive reason that led me to major in statistics, a discipline that deals with reality while maintaining the beauty of mathematics.
Based on academic distinctions at university, I had an opportunity to join an honor society named GLEAP, which I loved the motto of it; “Benefit the world corresponding to the academic excellence.” Working as a general executive director of GLEAP, I planned tutoring programs for underprivileged high school students related to elementary statistics. At first, students were indifferent to programs. I soon understood their uncooperative attitude came from illness of mind caused by hardships in life, and I had time playing with them and talking about their difficulties in life instead of programs. As I showed sincere interest in their lives, students began to open minds and finally actively participated in programs enjoying the pure pleasure of learning. Through this fulfilling experience, I could understand the worth of helping others and the gratification of seeing them change their lives better. Also, through academic exchange with Singapore university students, I realized that despite various backgrounds, we all have the same enthusiasm to study and wonder how to benefit the world in our own ways. GLEAP enabled me to reinforce my belief, devoting to a community with my knowledge, and to understand there are a lot of excellent scholars internationally, and there is no reason to restrict myself only in my nation.
A turning point in my life came when I was in the army. One day, one of my comrades suddenly collapsed and hyperventilated with an unknown cause. While taking care of him about one month, my thought was like, “Why doctors cannot find the cause of his disease and provide appropriate medications?” Seeing his face drawn with unexplained pain, I wanted to find a way of aiding people who suffer from diseases of unknown etiology. Although I am not a physician, what if I provide statistical backgrounds for suitable medical service? I thoroughly felt the importance of biostatistics that can back up the dream of personalized medicine. After discharge from the military, I noticed that there is a biostatistics laboratory in the university, so I joined the laboratory to get to know what the biostatistics is and how this field of study can benefit humanity.
Up to my undergraduate years, my life was experiencing new fields of study and appreciating the great joy of learning. From now on, I desire to contribute to a society based on my studies. Research experience in the biostatistics lab was engaging, and I soon became eager to study more about it in the topmost research environment with prominent faculty and colleagues. That is why I am applying for the Ph.D. program in biostatistics in [School]. Should there are any obstacles while earning a Ph.D., I will always recall my belief to dedicate to the world.
"
words_freq_analysis(ph)
x1 = c(204.4,556.6)
x2 = c(130.0,355.0)
S1 = matrix(c(13825.3, 23823.4, 23823.4, 73107.4), nrow = 2)
S2 = matrix(c(8632.0, 19616.7, 19616.7, 55964.5), nrow = 2)
x1 - x2
((n1-1)*S1+(n2-1)*S2)/(n1+n2-2)
n1 = 45
n2 = 55
((n1-1)*S1+(n2-1)*S2)/(n1+n2-2)
qf(0.05,p,n1+n2-p-1)
qf(0.95,p,n1+n2-p-1)
qf(0.95,p,n1+n2-p-1) *(1/n1+1/n2)*p*(n1+n2-2)/(n1+n2-p-1)
sp = ((n1-1)*S1+(n2-1)*S2)/(n1+n2-2)
svd(sp)
(c * 71323.4)**1/2
c = qf(0.95,p,n1+n2-p-1) *(1/n1+1/n2)*p*(n1+n2-2)/(n1+n2-p-1)
(c * 71323.4)**1/2
(c * 71323.4)**0.5
(c * 3301.572)**0.5
data <- iris
View(data)
iris
iris$Species == 'setosa'
data <- data[!data$Species == 'setosa',]
data
data_p <- data[data$Species == 'versicolor',]
data_p
data_n <- data[data$Species == 'virginica',]
data_n
mean(data_p,1)
mean(data_p)
data <- iris
data_p <- data[data$Species == 'versicolor',-4]
data_n <- data[data$Species == 'virginica',-4]
data_p
data_n
mean(data_p)
dim(data)
data
data <- iris
data_p <- data[data$Species == 'versicolor',-5]
data_n <- data[data$Species == 'virginica',-5]
mean(data_p)
data_p
mean(data_p)
sum(data_p)
colMeans(data_p)
sp = cov(data_p)
sp
(xp = colMeans(data_p))
(sp = cov(data_p))
n.p <- nrow(data_p)
n.n <- nrow(data_p)
n.p
n.n
data_p
classifier <- function(x) dmvnorm(x, mean = xp, sigma = sp) / dmvnorm(x, mean = xn, sigma = sn) > 0.1
for(i in 1:50){
prediction_p[i] <- classifier(data_p[i,])
}
library("Mvnorm")
library("mvtnorm")
classifier <- function(x) dmvnorm(x, mean = xp, sigma = sp) / dmvnorm(x, mean = xn, sigma = sn) > 0.1
for(i in 1:50){
prediction_p[i] <- classifier(data_p[i,])
}
data <- iris
data_p <- data[data$Species == 'versicolor',-5]
n.p <- nrow(data_p)
data_n <- data[data$Species == 'virginica',-5]
n.n <- nrow(data_p)
(xp = colMeans(data_p))
(sp = cov(data_p))
(xn = colMeans(data_n))
(sn = cov(data_n))
library("mvtnorm")
classifier <- function(x) dmvnorm(x, mean = xp, sigma = sp) / dmvnorm(x, mean = xn, sigma = sn) > 0.1
for(i in 1:50){
prediction_p[i] <- classifier(data_p[i,])
}
library("mvtnorm")
classifier <- function(x) dmvnorm(x, mean = xp, sigma = sp) / dmvnorm(x, mean = xn, sigma = sn) > 0.1
for(i in 1:50){
data_p$prediction[i] <- classifier(data_p[i,])
}
xp
sp
data_p[i,]
data_p
data <- iris
data[data$Species != 'sentosa',]
data
data <- iris
data[data$Species != 'setosa',]
data
data <- iris
data[data$Species != 'setosa',]
data_p <- data[data$Species == 'versicolor',-5]
no.p <- nrow(data_p)
data_n <- data[data$Species == 'virginica',-5]
no.n <- nrow(data_p)
(xp = colMeans(data_p))
(sp = cov(data_p))
(xn = colMeans(data_n))
(sn = cov(data_n))
(prob.p = no.p/(no.p+no.n))
(prob.n = no.n/(no.p+no.n))
library("mvtnorm")
classifier <- function(x){
if(dmvnorm(x, mean = xp, sigma = sp) / dmvnorm(x, mean = xn, sigma = sn) > 0.1){
return('versicolor')
}
else return('virginica')
}
for(i in 1:nrow(data)){
data$prediction[i] <- classifier(data[i,-5])
}
data[i,-5]
data
data <- iris
data <- iris
data <- data[data$Species != 'setosa',]
data
data <- iris
data <- data[data$Species != 'setosa',]
data_p <- data[data$Species == 'versicolor',-5]
no.p <- nrow(data_p)
data_n <- data[data$Species == 'virginica',-5]
no.n <- nrow(data_p)
(xp = colMeans(data_p))
(sp = cov(data_p))
(xn = colMeans(data_n))
(sn = cov(data_n))
(prob.p = no.p/(no.p+no.n))
(prob.n = no.n/(no.p+no.n))
library("mvtnorm")
classifier <- function(x){
if(dmvnorm(x, mean = xp, sigma = sp) / dmvnorm(x, mean = xn, sigma = sn) > 0.1){
return('versicolor')
}
else return('virginica')
}
for(i in 1:nrow(data)){
data$prediction[i] <- classifier(data[i,-5])
}
data
(xp = colMeans(data_p))
data <- iris
data <- data[data$Species != 'setosa',]
x <- data[5,-5]
x
classifier(x)
x <- data[78,-5]
classifier(x)
x <- data[3,-5]
classifier(x)
ResNet14_BLKD <- read.csv("ResNet14 BLKD.csv", header = F)
setwd("C:/Users/LCH/Desktop/Senior 2nd, 2019 fall/Deep learning Statistical perspective/Final project")
getwd()
ResNet14_BLKD <- read.csv("ResNet14 BLKD.csv", header = F)
ResNet14_GSKD <- read.csv("ResNet14 GSKD.csv", header = F)
anova <- function(data){
Acc = c()
setting = c()
for(i in 1:nrow(data)){
for(j in 1:(ncol(data)-1)){
Acc <- c(Acc, data[i,j+1])
setting <- c(setting, data[i,1])
}
}
data_df <- data.frame(Acc = Acc, setting = as.factor(setting))
data_ANOVA<-aov(Acc~setting, data=data_df)
return(data_ANOVA) #, bartlett.test(Acc~setting, data=data_df)))
}
summary(anova(ResNet14_BLKD))
ResNet14_BLKD
dd <- ResNet14_BLKD[-c(5,6),]
summary(anova(dd))
summary(anova(ResNet14_GSKD))
summary(anova(ResNet14_GSKD[-c(5,6),]))
ResNet14_GSKD <- read.csv("ResNet14 GSKD.csv", header = F)
ResNet14_GSKD
ResNet20_GSKD <- read.csv("ResNet20 GSKD.csv", header = F)
ResNet20_GSKD
ResNet26_GSKD <- read.csv("ResNet26 GSKD.csv", header = F)
ResNet26_GSKD
ResNet14_BLKD <- read.csv("ResNet14 BLKD.csv", header = F)
ResNet20_BLKD <- read.csv("ResNet20 BLKD.csv", header = F)
ResNet26_BLKD <- read.csv("ResNet26 BLKD.csv", header = F)
ResNet14_GSKD <- read.csv("ResNet14 GSKD.csv", header = F)
ResNet20_GSKD <- read.csv("ResNet20 GSKD.csv", header = F)
ResNet26_GSKD <- read.csv("ResNet26 GSKD.csv", header = F)
anova <- function(data){
Acc = c()
setting = c()
for(i in 1:nrow(data)){
for(j in 1:(ncol(data)-1)){
Acc <- c(Acc, data[i,j+1])
setting <- c(setting, data[i,1])
}
}
data_df <- data.frame(Acc = Acc, setting = as.factor(setting))
data_ANOVA<-aov(Acc~setting, data=data_df)
return(data_ANOVA) #, bartlett.test(Acc~setting, data=data_df)))
}
summary(anova(ResNet14_BLKD))
summary(anova(ResNet14_BLKD))
summary(anova(ResNet14_GSKD))
summary(anova(ResNet14_BLKD[-c(5,6),]))
summary(anova(ResNet14_GSKD[-c(5,6),]))
summary(anova(ResNet20_BLKD))
summary(anova(ResNet20_GSKD))
summary(anova(ResNet20_BLKD[-c(5,6),]))
summary(anova(ResNet20_GSKD[-c(5,6),]))
summary(anova(ResNet26_BLKD))
summary(anova(ResNet26_GSKD))
summary(anova(ResNet26_BLKD[-c(5,6),]))
summary(anova(ResNet26_GSKD[-c(5,6),]))
summary(anova(ResNet14_BLKD[-c(5,6),]))
summary(anova(ResNet14_GSKD[-c(5,6),]))
summary(anova(ResNet20_BLKD[-c(5,6),]))
summary(anova(ResNet20_GSKD[-c(5,6),]))
summary(anova(ResNet26_BLKD[-c(5,6),]))
summary(anova(ResNet26_GSKD[-c(5,6),]))
ResNet14_BLKD
library(plyr)
library(reshape2)
(melted <- melt(ResNet14_BLKD, id.vars=c("V1")))
ddply(melted, c("V1"), summarise, mean = mean(value), sd = sd(value))
mean(ResNet14_BLKD[9,])
ResNet14_BLKD[9,]
ResNet14_BLKD[9,2:]
ResNet14_BLKD[9,2:5]
mean(ResNet14_BLKD[9,2:5])
mean(ResNet14_BLKD[9,2:5])
ResNet14_BLKD[9,2:5]
8829+8836+8858+8819
35342/4
