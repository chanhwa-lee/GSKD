{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CH_mkstudent.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"knON_BzvVZAj","colab_type":"code","outputId":"db4dab84-f6cd-43d2-e5d1-8ed61fcfdf20","executionInfo":{"status":"ok","timestamp":1575442966573,"user_tz":-540,"elapsed":20148,"user":{"displayName":"이찬화","photoUrl":"","userId":"08529154005167969207"}},"colab":{"base_uri":"https://localhost:8080/","height":127}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"aoFdMB6faxgl","colab_type":"code","colab":{}},"source":["def load_checkpoint(model, checkpoint_path):\n","    model_ckp = torch.load(checkpoint_path)\n","    model.load_state_dict(model_ckp['model_state_dict'])\n","    return model\n","\n","class NewTrainManager(object):\n","    def __init__(self, student, teacher=None, young=None, train_loader=None, test_loader=None, train_config={}):\n","        self.student = student\n","        self.teacher = teacher\n","        self.young = young\n"," \n","        self.have_teacher = bool(self.teacher)\n","        self.have_young = bool(self.young)\n"," \n","        self.device = train_config['device'] #cuda or cpu\n","        self.name = train_config['name'] #current training model's name\n","        self.optimizer = optim.SGD(self.student.parameters(),\n","                                   lr=train_config['learning_rate'],\n","                                   momentum=train_config['momentum'],\n","                                   weight_decay=train_config['weight_decay'])\n","        if self.have_teacher:\n","            self.teacher.eval()\n","            self.teacher.train(mode=False)\n"," \n","        if self.have_young:\n","            self.young.eval()\n","            self.young.train(mode=False)\n","            \n","        self.train_loader = train_loader\n","        self.test_loader = test_loader\n","        self.config = train_config\n"," \n","        self.best_epoch = 0\n","        self.best_accuracy = 0\n","    \n","    def train(self):\n","        lambda_ = self.config['lambda_student']\n","        gamma_ = self.config['gamma']\n","        T = self.config['T_student']\n"," \n","        epochs = self.config['epochs']\n","        trial_id = self.config['trial_id']\n","        \n","        max_val_acc = 0\n","        iteration = 0\n","        best_acc = 0\n","        best_epo = 0\n","        criterion = nn.CrossEntropyLoss()\n","        \n","        training_time = time.time()\n","        #print(\"여기1\")\n","        for epoch in range(1, epochs+1):\n","            start_time = time.time()\n","            self.student.train()\n","            self.adjust_learning_rate(self.optimizer, epoch)\n","            loss = 0\n","            #print(\"여기2\")\n","            for batch_idx, (data, target) in enumerate(self.train_loader):\n","                iteration += 1\n","                data = data.to(self.device)\n","                target = target.to(self.device)\n","                self.optimizer.zero_grad()\n","                output = self.student(data)\n","                # Standard Learning Loss ( Classification Loss)\n","                loss_SL = criterion(output, target) \n","                loss = loss_SL\n","\n","                #print(\"여기3\")\n","\n","                if self.have_teacher:\n","                    teacher_outputs = self.teacher(data)\n","                    # Knowledge Distillation Loss\n","                    loss_KD = nn.KLDivLoss()(F.log_softmax(output / T, dim=1),\n","                                                      F.softmax(teacher_outputs / T, dim=1))\n","                    loss = (1 - lambda_) * loss_SL + lambda_ * T * T * loss_KD\n","                    #print(\"여기4\")\n","\n","                    if self.have_young:\n","                        young_outputs = self.young(data)\n","                        # ReverseKD from younger to older\n","                        loss_ReKD = nn.KLDivLoss()(F.log_softmax(output / T, dim=1),\n","                                                      F.softmax(young_outputs / T, dim = 1))\n","                        loss = (1 - lambda_ - gamma_) * loss_SL + lambda_ * T * T * loss_KD + gamma_ * T * T * loss_ReKD\n","                    \n","                loss.backward()\n","                self.optimizer.step()\n","            \n","            print(\"epoch {0}/{1} --- {2:0.3f} seconds --- \".format(epoch, epochs, time.time() - start_time))\n","            val_acc = self.validate(step=epoch)\n","            if val_acc > best_acc:\n","                best_acc = val_acc\n","                best_epoch = epoch\n","                self.save(epoch, name='{}_{}_{}_{}_{}_best.pth.tar'.format(self.name, trial_id, T, lambda_, gamma_))\n","        save_model = create_cnn_model(self.name, 'cifar10', use_cuda=True)\n","        save_model = load_checkpoint(save_model, os.path.join('./','{}_{}_{}_{}_{}_best.pth.tar'.format(self.name, trial_id, T, lambda_, gamma_)))\n","        torch.save({\n","                'model_state_dict': save_model.state_dict(),\n","                # 'optimizer_state_dict': save_model.optimizer.state_dict(),\n","                'epoch': best_epoch,\n","            }, '{}_{}_{}_{}_{}_{}_best.pth.tar'.format(best_acc,self.name, trial_id, T, lambda_, gamma_))\n","        print(\"Total elapsed time : {0:0.3f} seconds --- \".format(time.time() - training_time))\n","        print(\"Best accuracy was : {}\".format(best_acc))\n","        return best_acc\n","    \n","    def validate(self, step=0):\n","        self.student.eval()\n","        with torch.no_grad():\n","            correct = 0\n","            total = 0\n","            acc = 0\n","            for images, labels in self.test_loader:\n","                images = images.to(self.device)\n","                labels = labels.to(self.device)\n","                outputs = self.student(images)\n","                _, predicted = torch.max(outputs.data, 1)\n","                total += labels.size(0)\n","                correct += (predicted == labels).sum().item()\n","            # self.accuracy_history.append(acc)\n","            acc = 100 * correct / total\n","            \n","            print('{{\"metric\": \"{}_val_accuracy\", \"value\": {}}}'.format(self.name, acc))\n","            return acc\n","    \n","    def save(self, epoch, name=None):\n","        trial_id = self.config['trial_id']\n","        if name is None:\n","            torch.save({\n","                'epoch': epoch,\n","                'model_state_dict': self.student.state_dict(),\n","                'optimizer_state_dict': self.optimizer.state_dict(),\n","            }, '{}_{}_epoch{}.pth.tar'.format(self.name, trial_id, epoch))\n","        else:\n","            torch.save({\n","                'model_state_dict': self.student.state_dict(),\n","                'optimizer_state_dict': self.optimizer.state_dict(),\n","                'epoch': epoch,\n","            }, name)\n","    \n","    def adjust_learning_rate(self, optimizer, epoch):\n","        epochs = self.config['epochs']\n","        models_are_plane = self.config['is_plane']\n","        \n","        # depending on dataset\n","        if models_are_plane:\n","            lr = 0.01\n","        else:\n","            if epoch < int(epoch/2.0):\n","                lr = 0.1\n","            elif epoch < int(epochs*3/4.0):\n","                lr = 0.1 * 0.1\n","            else:\n","                lr = 0.1 * 0.01\n","        \n","        # update optimizer's learning rate\n","        for param_group in optimizer.param_groups:\n","            param_group['lr'] = lr"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AsdAyw-AZsDA","colab_type":"code","colab":{}},"source":["import os\n","os.chdir('/content/drive/My Drive/Colab Notebooks/DLF/student')\n","import copy\n","import math\n","import torch\n","import torch.nn as nn\n","import torchvision\n","import torchvision.datasets as datasets\n","import torchvision.transforms as transforms\n","import torchvision.models as torch_models\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import time\n","import sys\n","sys.path.append('/content/drive/My Drive/Colab Notebooks/DLF/TaKD')\n","\n","import data_loader\n","import model_factory\n","import plain_cnn_cifar\n","import resnet_cifar\n","\n","from data_loader import get_cifar\n","from model_factory import create_cnn_model, is_resnet\n","\n","from resnet_cifar import *\n","from plain_cnn_cifar import *"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SBVak5mKS-J4","colab_type":"code","outputId":"9584494c-a4f7-4fd7-8ea4-2e50d5d70d19","executionInfo":{"status":"ok","timestamp":1575353763935,"user_tz":-540,"elapsed":15363,"user":{"displayName":"이찬화","photoUrl":"","userId":"08529154005167969207"}},"colab":{"base_uri":"https://localhost:8080/","height":53}},"source":["myname = \"CH\"\n","batch_size = 128\n","\n","dataset = 'cifar10'\n","num_classes = 10 # 10 or 100\n","train_loader, test_loader = get_cifar(num_classes, dataset_dir='/content/drive/My Drive/Colab Notebooks/DLF/cifar/crop', batch_size=batch_size, crop = True)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Files already downloaded and verified\n","Files already downloaded and verified\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"L6F0Iwe7EN6o","colab_type":"text"},"source":["# Making student"]},{"cell_type":"code","metadata":{"id":"BjIqHFWTc7ju","colab_type":"code","outputId":"043aeefd-54fa-40d0-b003-9b0435b2f8b2","executionInfo":{"status":"ok","timestamp":1575353770339,"user_tz":-540,"elapsed":17691,"user":{"displayName":"이찬화","photoUrl":"","userId":"08529154005167969207"}},"colab":{"base_uri":"https://localhost:8080/","height":53}},"source":["# teacher_checkpoint = '/content/drive/My Drive/Colab Notebooks/DLF/teacher/' + str(teacher_name)\n","\n","teacher = 'resnet26' # input teacher's model\n","teacher_checkpoint =  '/content/drive/My Drive/Colab Notebooks/DLF/teacher/resnet26_paik_20_128 # 4_best.pth.tar'\n","# copy and paste teacher's path\n","\n","teacher_model = create_cnn_model(teacher, dataset, use_cuda=True)\n","print(\"---------- Loading Teacher -------\")\n","teacher_model = load_checkpoint(teacher_model, teacher_checkpoint)\n","print(\"대여\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["---------- Loading Teacher -------\n","대여\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6WRHnS_OEyJ1","colab_type":"code","outputId":"8f05cae8-08da-415d-c22e-cf468a2f6ce8","executionInfo":{"status":"ok","timestamp":1575280224188,"user_tz":-540,"elapsed":4042584,"user":{"displayName":"이찬화","photoUrl":"","userId":"08529154005167969207"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["epochs = 80\n","lambda_ = 0.1\n","gamma_ = 0.05\n","trial_num = 1\n","chseed = 20 # 20 31 55\n","torch.manual_seed(chseed); torch.cuda.manual_seed(chseed)\n","trial_id = myname + \"_\" + str(chseed) +\"_\" + str(batch_size) + \" # \" + str(trial_num)\n","\n","student = 'resnet8'\n","student_model = create_cnn_model(student, dataset, use_cuda=True)\n","\n","train_config = {\n","\t\t'epochs': epochs,\n","\t\t'learning_rate': 0.1,\n","\t\t'momentum': 0.9,\n","\t\t'weight_decay': 0.0001,\n","\t\t'device': 'cuda',\n","\t\t'is_plane': False,\n","\t\t'trial_id': trial_id,\n","\t\t'name': student,\n","    'T_student': 3, #config.get('T_student')\n","\t\t'lambda_student': lambda_, #config.get('lambda_student')\n","\t\t'gamma' : gamma_ # \n","\t}\n","  \n","young = ''\n","young_checkpoint = ''\n","# copy and paste\n","\n","if young:\n","    print(\"---------- Loading Young -------\")\n","    young_model = create_cnn_model(young, dataset, use_cuda=True)\n","    young_model = load_checkpoint(young_model, young_checkpoint)\n","    student_trainer = NewTrainManager(student_model, teacher=teacher_model, young = young_model, train_loader=train_loader, test_loader=test_loader, train_config=train_config)\n","    student_trainer.train()\n","else:\n","    print(\"---------- Without Young -------\")\n","    student_trainer = NewTrainManager(student_model, teacher=teacher_model, young = None, train_loader=train_loader, test_loader=test_loader, train_config=train_config)\n","    print(1)\n","    student_trainer.train() "],"execution_count":0,"outputs":[{"output_type":"stream","text":["---------- Without Young -------\n","1\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1946: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n","  warnings.warn(\"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n"],"name":"stderr"},{"output_type":"stream","text":["epoch 1/80 --- 48.509 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 38.01}\n","epoch 2/80 --- 48.380 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 46.11}\n","epoch 3/80 --- 48.316 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 50.21}\n","epoch 4/80 --- 48.303 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 53.6}\n","epoch 5/80 --- 48.362 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 58.12}\n","epoch 6/80 --- 48.342 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 61.86}\n","epoch 7/80 --- 48.355 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 61.2}\n","epoch 8/80 --- 48.368 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 60.13}\n","epoch 9/80 --- 48.328 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 63.4}\n","epoch 10/80 --- 48.358 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 66.97}\n","epoch 11/80 --- 48.346 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 68.25}\n","epoch 12/80 --- 48.338 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 69.02}\n","epoch 13/80 --- 48.360 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 69.26}\n","epoch 14/80 --- 48.386 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 68.32}\n","epoch 15/80 --- 48.371 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 71.83}\n","epoch 16/80 --- 48.349 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 71.46}\n","epoch 17/80 --- 48.364 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 71.0}\n","epoch 18/80 --- 48.361 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 72.75}\n","epoch 19/80 --- 48.353 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 74.98}\n","epoch 20/80 --- 48.336 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 74.95}\n","epoch 21/80 --- 48.370 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 73.49}\n","epoch 22/80 --- 48.361 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 73.85}\n","epoch 23/80 --- 48.338 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 74.84}\n","epoch 24/80 --- 48.343 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 74.6}\n","epoch 25/80 --- 48.364 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 77.0}\n","epoch 26/80 --- 48.141 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 74.53}\n","epoch 27/80 --- 47.931 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 78.34}\n","epoch 28/80 --- 47.925 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 76.52}\n","epoch 29/80 --- 47.896 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 75.81}\n","epoch 30/80 --- 48.116 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 77.99}\n","epoch 31/80 --- 48.130 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 74.49}\n","epoch 32/80 --- 48.242 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 77.07}\n","epoch 33/80 --- 48.250 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 75.81}\n","epoch 34/80 --- 48.270 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 78.79}\n","epoch 35/80 --- 48.247 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 78.68}\n","epoch 36/80 --- 48.301 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 76.52}\n","epoch 37/80 --- 48.271 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 78.21}\n","epoch 38/80 --- 48.210 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 80.7}\n","epoch 39/80 --- 48.261 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 79.21}\n","epoch 40/80 --- 48.298 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 78.83}\n","epoch 41/80 --- 48.235 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 80.58}\n","epoch 42/80 --- 48.239 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 78.95}\n","epoch 43/80 --- 48.238 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 80.43}\n","epoch 44/80 --- 48.267 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 81.07}\n","epoch 45/80 --- 48.222 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 80.47}\n","epoch 46/80 --- 48.255 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 80.4}\n","epoch 47/80 --- 48.246 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 78.64}\n","epoch 48/80 --- 48.257 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 81.21}\n","epoch 49/80 --- 48.278 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 80.04}\n","epoch 50/80 --- 48.289 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 80.57}\n","epoch 51/80 --- 48.278 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 79.08}\n","epoch 52/80 --- 48.237 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 80.7}\n","epoch 53/80 --- 48.232 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 80.19}\n","epoch 54/80 --- 48.211 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 78.58}\n","epoch 55/80 --- 48.240 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 81.62}\n","epoch 56/80 --- 48.243 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 81.71}\n","epoch 57/80 --- 48.220 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 82.24}\n","epoch 58/80 --- 48.226 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 81.8}\n","epoch 59/80 --- 48.085 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 79.3}\n","epoch 60/80 --- 48.020 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 84.05}\n","epoch 61/80 --- 48.192 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 84.2}\n","epoch 62/80 --- 48.233 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 84.31}\n","epoch 63/80 --- 48.245 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 84.25}\n","epoch 64/80 --- 48.208 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 84.36}\n","epoch 65/80 --- 48.196 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 84.39}\n","epoch 66/80 --- 48.188 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 84.51}\n","epoch 67/80 --- 48.168 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 84.54}\n","epoch 68/80 --- 48.121 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 84.44}\n","epoch 69/80 --- 48.192 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 84.58}\n","epoch 70/80 --- 48.215 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 84.39}\n","epoch 71/80 --- 48.198 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 84.46}\n","epoch 72/80 --- 48.187 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 84.43}\n","epoch 73/80 --- 48.184 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 84.28}\n","epoch 74/80 --- 48.212 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 84.31}\n","epoch 75/80 --- 48.067 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 84.46}\n","epoch 76/80 --- 48.206 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 84.22}\n","epoch 77/80 --- 48.188 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 84.27}\n","epoch 78/80 --- 48.207 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 84.53}\n","epoch 79/80 --- 48.177 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 84.38}\n","epoch 80/80 --- 48.254 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 84.41}\n","Total elapsed time : 4041.164 seconds --- \n","Best accuracy was : 84.58\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"S8bqX-Qpixa8","colab_type":"code","outputId":"fcfc9dd7-d3fa-4289-9bc6-10fd6a5aa637","executionInfo":{"status":"ok","timestamp":1575288564852,"user_tz":-540,"elapsed":25,"user":{"displayName":"이찬화","photoUrl":"","userId":"08529154005167969207"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["epochs = 80\n","lambda_ = 0.1\n","gamma_ = 0.8\n","trial_num = 2\n","chseed = 20 # 20 31 55\n","torch.manual_seed(chseed); torch.cuda.manual_seed(chseed)\n","trial_id = myname + \"_\" + str(chseed) +\"_\" + str(batch_size) + \" # \" + str(trial_num)\n","\n","student = 'resnet8'\n","student_model = create_cnn_model(student, dataset, use_cuda=True)\n","\n","train_config = {\n","\t\t'epochs': epochs,\n","\t\t'learning_rate': 0.1,\n","\t\t'momentum': 0.9,\n","\t\t'weight_decay': 0.0001,\n","\t\t'device': 'cuda',\n","\t\t'is_plane': False,\n","\t\t'trial_id': trial_id,\n","\t\t'name': student,\n","    'T_student': 3, #config.get('T_student')\n","\t\t'lambda_student': lambda_, #config.get('lambda_student')\n","\t\t'gamma' : gamma_ # \n","\t}\n","\n","young = ''\n","young_checkpoint = ''\n","# copy and paste\n","\n","if young:\n","    print(\"---------- Loading Young -------\")\n","    young_model = create_cnn_model(young, dataset, use_cuda=True)\n","    young_model = load_checkpoint(young_model, young_checkpoint)\n","    student_trainer = NewTrainManager(student_model, teacher=teacher_model, young = young_model, train_loader=train_loader, test_loader=test_loader, train_config=train_config)\n","    student_trainer.train()\n","else:\n","    print(\"---------- Without Young -------\")\n","    student_trainer = NewTrainManager(student_model, teacher=teacher_model, young = None, train_loader=train_loader, test_loader=test_loader, train_config=train_config)\n","    print(1)\n","    student_trainer.train() "],"execution_count":0,"outputs":[{"output_type":"stream","text":["---------- Without Young -------\n","1\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1946: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n","  warnings.warn(\"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n"],"name":"stderr"},{"output_type":"stream","text":["epoch 1/80 --- 48.299 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 38.16}\n","epoch 2/80 --- 48.154 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 46.47}\n","epoch 3/80 --- 48.190 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 52.6}\n","epoch 4/80 --- 48.181 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 54.21}\n","epoch 5/80 --- 48.179 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 56.57}\n","epoch 6/80 --- 48.197 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 63.04}\n","epoch 7/80 --- 48.185 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 61.55}\n","epoch 8/80 --- 48.134 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 61.94}\n","epoch 9/80 --- 48.181 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 64.23}\n","epoch 10/80 --- 48.155 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 65.3}\n","epoch 11/80 --- 48.139 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 67.42}\n","epoch 12/80 --- 48.202 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 68.1}\n","epoch 13/80 --- 48.159 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 66.54}\n","epoch 14/80 --- 48.155 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 70.98}\n","epoch 15/80 --- 48.152 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 70.97}\n","epoch 16/80 --- 48.184 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 71.56}\n","epoch 17/80 --- 48.177 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 69.82}\n","epoch 18/80 --- 48.172 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 72.47}\n","epoch 19/80 --- 48.160 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 74.38}\n","epoch 20/80 --- 47.999 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 70.61}\n","epoch 21/80 --- 48.141 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 73.67}\n","epoch 22/80 --- 47.984 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 75.65}\n","epoch 23/80 --- 47.900 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 75.76}\n","epoch 24/80 --- 47.903 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 74.11}\n","epoch 25/80 --- 47.974 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 75.94}\n","epoch 26/80 --- 47.550 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 72.37}\n","epoch 27/80 --- 48.173 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 77.15}\n","epoch 28/80 --- 48.320 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 74.95}\n","epoch 29/80 --- 48.230 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 77.44}\n","epoch 30/80 --- 48.258 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 77.46}\n","epoch 31/80 --- 48.239 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 75.96}\n","epoch 32/80 --- 48.426 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 75.86}\n","epoch 33/80 --- 48.409 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 74.85}\n","epoch 34/80 --- 48.456 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 76.18}\n","epoch 35/80 --- 48.478 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 78.73}\n","epoch 36/80 --- 48.285 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 77.98}\n","epoch 37/80 --- 48.026 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 79.52}\n","epoch 38/80 --- 48.235 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 78.98}\n","epoch 39/80 --- 48.307 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 79.49}\n","epoch 40/80 --- 48.484 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 77.89}\n","epoch 41/80 --- 48.446 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 79.22}\n","epoch 42/80 --- 48.545 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 78.98}\n","epoch 43/80 --- 48.542 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 79.04}\n","epoch 44/80 --- 48.483 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 80.44}\n","epoch 45/80 --- 48.543 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 79.48}\n","epoch 46/80 --- 48.565 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 80.32}\n","epoch 47/80 --- 48.466 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 80.08}\n","epoch 48/80 --- 48.438 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 80.99}\n","epoch 49/80 --- 48.597 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 80.44}\n","epoch 50/80 --- 48.564 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 81.05}\n","epoch 51/80 --- 48.590 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 79.71}\n","epoch 52/80 --- 48.622 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 81.39}\n","epoch 53/80 --- 48.623 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 79.33}\n","epoch 54/80 --- 48.558 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 81.45}\n","epoch 55/80 --- 48.483 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 82.01}\n","epoch 56/80 --- 48.634 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 79.82}\n","epoch 57/80 --- 48.488 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 81.91}\n","epoch 58/80 --- 48.501 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 79.31}\n","epoch 59/80 --- 48.502 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 82.24}\n","epoch 60/80 --- 48.563 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 84.22}\n","epoch 61/80 --- 48.486 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 84.33}\n","epoch 62/80 --- 48.610 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 84.07}\n","epoch 63/80 --- 48.503 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 84.17}\n","epoch 64/80 --- 48.472 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 84.29}\n","epoch 65/80 --- 48.504 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 84.14}\n","epoch 66/80 --- 48.482 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 84.34}\n","epoch 67/80 --- 48.502 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 83.92}\n","epoch 68/80 --- 48.611 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 84.08}\n","epoch 69/80 --- 48.223 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 83.96}\n","epoch 70/80 --- 48.197 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 84.27}\n","epoch 71/80 --- 48.148 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 84.48}\n","epoch 72/80 --- 48.321 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 84.3}\n","epoch 73/80 --- 48.191 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 84.11}\n","epoch 74/80 --- 48.142 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 84.14}\n","epoch 75/80 --- 47.909 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 84.19}\n","epoch 76/80 --- 47.840 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 84.22}\n","epoch 77/80 --- 47.876 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 84.26}\n","epoch 78/80 --- 47.846 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 84.19}\n","epoch 79/80 --- 47.886 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 84.51}\n","epoch 80/80 --- 47.851 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 84.32}\n","Total elapsed time : 4050.370 seconds --- \n","Best accuracy was : 84.51\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7uUW_dYcAxrN","colab_type":"code","outputId":"1e5f9bf2-3d60-4324-9d57-4dc3e398ed49","executionInfo":{"status":"ok","timestamp":1575292754859,"user_tz":-540,"elapsed":4018114,"user":{"displayName":"이찬화","photoUrl":"","userId":"08529154005167969207"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["epochs = 80\n","lambda_ = 0.4\n","gamma_ = 0.1\n","trial_num = 3\n","chseed = 20 # 20 31 55\n","torch.manual_seed(chseed); torch.cuda.manual_seed(chseed)\n","trial_id = myname + \"_\" + str(chseed) +\"_\" + str(batch_size) + \" # \" + str(trial_num)\n","\n","student = 'resnet8'\n","student_model = create_cnn_model(student, dataset, use_cuda=True)\n","\n","train_config = {\n","\t\t'epochs': epochs,\n","\t\t'learning_rate': 0.1,\n","\t\t'momentum': 0.9,\n","\t\t'weight_decay': 0.0001,\n","\t\t'device': 'cuda',\n","\t\t'is_plane': False,\n","\t\t'trial_id': trial_id,\n","\t\t'name': student,\n","    'T_student': 3, #config.get('T_student')\n","\t\t'lambda_student': lambda_, #config.get('lambda_student')\n","\t\t'gamma' : gamma_ # \n","\t}\n","\n","young = ''\n","young_checkpoint = ''\n","# copy and paste\n","\n","if young:\n","    print(\"---------- Loading Young -------\")\n","    young_model = create_cnn_model(young, dataset, use_cuda=True)\n","    young_model = load_checkpoint(young_model, young_checkpoint)\n","    student_trainer = NewTrainManager(student_model, teacher=teacher_model, young = young_model, train_loader=train_loader, test_loader=test_loader, train_config=train_config)\n","    student_trainer.train()\n","else:\n","    print(\"---------- Without Young -------\")\n","    student_trainer = NewTrainManager(student_model, teacher=teacher_model, young = None, train_loader=train_loader, test_loader=test_loader, train_config=train_config)\n","    print(1)\n","    student_trainer.train() "],"execution_count":0,"outputs":[{"output_type":"stream","text":["---------- Without Young -------\n","1\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1946: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n","  warnings.warn(\"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n"],"name":"stderr"},{"output_type":"stream","text":["epoch 1/80 --- 48.167 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 36.83}\n","epoch 2/80 --- 47.762 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 43.64}\n","epoch 3/80 --- 47.904 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 49.46}\n","epoch 4/80 --- 47.938 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 52.99}\n","epoch 5/80 --- 47.927 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 54.31}\n","epoch 6/80 --- 47.902 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 59.92}\n","epoch 7/80 --- 47.972 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 59.52}\n","epoch 8/80 --- 47.933 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 62.07}\n","epoch 9/80 --- 47.941 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 65.31}\n","epoch 10/80 --- 47.941 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 66.46}\n","epoch 11/80 --- 47.942 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 65.53}\n","epoch 12/80 --- 47.933 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 66.3}\n","epoch 13/80 --- 47.932 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 67.07}\n","epoch 14/80 --- 47.915 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 68.49}\n","epoch 15/80 --- 47.920 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 70.87}\n","epoch 16/80 --- 47.928 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 71.49}\n","epoch 17/80 --- 47.945 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 66.83}\n","epoch 18/80 --- 47.983 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 70.3}\n","epoch 19/80 --- 47.932 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 72.64}\n","epoch 20/80 --- 47.911 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 72.02}\n","epoch 21/80 --- 47.959 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 66.59}\n","epoch 22/80 --- 47.747 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 74.89}\n","epoch 23/80 --- 47.816 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 74.56}\n","epoch 24/80 --- 47.917 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 74.28}\n","epoch 25/80 --- 47.903 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 75.44}\n","epoch 26/80 --- 47.937 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 72.71}\n","epoch 27/80 --- 47.816 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 76.34}\n","epoch 28/80 --- 47.881 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 76.44}\n","epoch 29/80 --- 47.894 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 75.95}\n","epoch 30/80 --- 47.893 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 77.43}\n","epoch 31/80 --- 47.944 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 75.85}\n","epoch 32/80 --- 47.908 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 77.6}\n","epoch 33/80 --- 47.970 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 75.66}\n","epoch 34/80 --- 47.936 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 76.63}\n","epoch 35/80 --- 47.989 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 76.92}\n","epoch 36/80 --- 47.969 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 78.61}\n","epoch 37/80 --- 47.949 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 79.2}\n","epoch 38/80 --- 47.949 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 76.9}\n","epoch 39/80 --- 47.987 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 78.13}\n","epoch 40/80 --- 47.977 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 74.68}\n","epoch 41/80 --- 47.968 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 78.86}\n","epoch 42/80 --- 47.918 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 78.32}\n","epoch 43/80 --- 47.947 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 79.45}\n","epoch 44/80 --- 47.844 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 78.66}\n","epoch 45/80 --- 47.937 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 78.47}\n","epoch 46/80 --- 47.936 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 79.56}\n","epoch 47/80 --- 47.930 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 77.4}\n","epoch 48/80 --- 47.976 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 80.65}\n","epoch 49/80 --- 47.917 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 79.75}\n","epoch 50/80 --- 47.937 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 80.47}\n","epoch 51/80 --- 47.963 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 78.72}\n","epoch 52/80 --- 47.940 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 80.27}\n","epoch 53/80 --- 47.953 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 80.55}\n","epoch 54/80 --- 47.967 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 80.28}\n","epoch 55/80 --- 47.918 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 81.3}\n","epoch 56/80 --- 47.951 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 79.19}\n","epoch 57/80 --- 47.915 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 80.76}\n","epoch 58/80 --- 47.904 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 76.99}\n","epoch 59/80 --- 47.943 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 81.46}\n","epoch 60/80 --- 47.961 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 83.27}\n","epoch 61/80 --- 47.939 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 83.37}\n","epoch 62/80 --- 47.949 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 83.32}\n","epoch 63/80 --- 47.925 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 83.54}\n","epoch 64/80 --- 47.983 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 83.63}\n","epoch 65/80 --- 47.964 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 83.53}\n","epoch 66/80 --- 47.916 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 83.65}\n","epoch 67/80 --- 47.891 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 83.34}\n","epoch 68/80 --- 47.895 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 83.57}\n","epoch 69/80 --- 47.881 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 83.45}\n","epoch 70/80 --- 47.902 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 83.34}\n","epoch 71/80 --- 47.953 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 83.62}\n","epoch 72/80 --- 47.897 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 83.78}\n","epoch 73/80 --- 47.927 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 83.64}\n","epoch 74/80 --- 47.851 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 83.6}\n","epoch 75/80 --- 47.914 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 83.63}\n","epoch 76/80 --- 47.875 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 83.84}\n","epoch 77/80 --- 47.921 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 83.65}\n","epoch 78/80 --- 47.906 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 83.63}\n","epoch 79/80 --- 47.875 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 83.57}\n","epoch 80/80 --- 48.207 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 83.66}\n","Total elapsed time : 4017.160 seconds --- \n","Best accuracy was : 83.84\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"z7evYKZcAxt1","colab_type":"code","outputId":"63567477-ffed-4f30-b38d-8e7da20abc2a","executionInfo":{"status":"ok","timestamp":1575297418495,"user_tz":-540,"elapsed":4046712,"user":{"displayName":"이찬화","photoUrl":"","userId":"08529154005167969207"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["epochs = 80\n","lambda_ = 0.4\n","gamma_ = 0.4\n","trial_num = 4\n","chseed = 20 # 20 31 55\n","torch.manual_seed(chseed); torch.cuda.manual_seed(chseed)\n","trial_id = myname + \"_\" + str(chseed) +\"_\" + str(batch_size) + \" # \" + str(trial_num)\n","\n","student = 'resnet8'\n","student_model = create_cnn_model(student, dataset, use_cuda=True)\n","\n","train_config = {\n","\t\t'epochs': epochs,\n","\t\t'learning_rate': 0.1,\n","\t\t'momentum': 0.9,\n","\t\t'weight_decay': 0.0001,\n","\t\t'device': 'cuda',\n","\t\t'is_plane': False,\n","\t\t'trial_id': trial_id,\n","\t\t'name': student,\n","    'T_student': 3, #config.get('T_student')\n","\t\t'lambda_student': lambda_, #config.get('lambda_student')\n","\t\t'gamma' : gamma_ # \n","\t}\n","\n","young = ''\n","young_checkpoint = ''\n","# copy and paste\n","\n","if young:\n","    print(\"---------- Loading Young -------\")\n","    young_model = create_cnn_model(young, dataset, use_cuda=True)\n","    young_model = load_checkpoint(young_model, young_checkpoint)\n","    student_trainer = NewTrainManager(student_model, teacher=teacher_model, young = young_model, train_loader=train_loader, test_loader=test_loader, train_config=train_config)\n","    student_trainer.train()\n","else:\n","    print(\"---------- Without Young -------\")\n","    student_trainer = NewTrainManager(student_model, teacher=teacher_model, young = None, train_loader=train_loader, test_loader=test_loader, train_config=train_config)\n","    print(1)\n","    student_trainer.train() "],"execution_count":0,"outputs":[{"output_type":"stream","text":["---------- Without Young -------\n","1\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1946: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n","  warnings.warn(\"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n"],"name":"stderr"},{"output_type":"stream","text":["epoch 1/80 --- 48.529 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 37.24}\n","epoch 2/80 --- 48.238 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 43.55}\n","epoch 3/80 --- 48.261 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 48.31}\n","epoch 4/80 --- 48.186 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 52.85}\n","epoch 5/80 --- 48.273 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 55.39}\n","epoch 6/80 --- 48.200 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 58.57}\n","epoch 7/80 --- 48.197 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 58.09}\n","epoch 8/80 --- 48.185 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 61.8}\n","epoch 9/80 --- 48.209 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 63.54}\n","epoch 10/80 --- 48.225 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 66.54}\n","epoch 11/80 --- 48.363 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 67.36}\n","epoch 12/80 --- 48.212 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 66.99}\n","epoch 13/80 --- 48.229 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 66.71}\n","epoch 14/80 --- 48.189 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 68.49}\n","epoch 15/80 --- 48.198 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 69.81}\n","epoch 16/80 --- 48.197 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 71.75}\n","epoch 17/80 --- 48.217 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 68.41}\n","epoch 18/80 --- 48.182 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 71.38}\n","epoch 19/80 --- 48.202 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 73.64}\n","epoch 20/80 --- 48.214 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 70.61}\n","epoch 21/80 --- 48.228 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 68.64}\n","epoch 22/80 --- 48.191 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 74.69}\n","epoch 23/80 --- 48.252 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 75.16}\n","epoch 24/80 --- 48.219 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 75.54}\n","epoch 25/80 --- 48.201 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 76.1}\n","epoch 26/80 --- 48.195 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 73.29}\n","epoch 27/80 --- 48.187 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 76.41}\n","epoch 28/80 --- 48.137 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 77.58}\n","epoch 29/80 --- 48.192 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 75.96}\n","epoch 30/80 --- 48.225 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 76.63}\n","epoch 31/80 --- 48.220 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 77.24}\n","epoch 32/80 --- 48.226 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 77.03}\n","epoch 33/80 --- 48.189 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 75.27}\n","epoch 34/80 --- 48.167 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 76.82}\n","epoch 35/80 --- 48.219 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 78.79}\n","epoch 36/80 --- 48.206 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 77.76}\n","epoch 37/80 --- 48.249 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 78.16}\n","epoch 38/80 --- 48.314 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 78.72}\n","epoch 39/80 --- 48.262 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 76.91}\n","epoch 40/80 --- 48.258 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 78.08}\n","epoch 41/80 --- 48.042 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 79.07}\n","epoch 42/80 --- 48.343 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 78.56}\n","epoch 43/80 --- 48.191 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 79.09}\n","epoch 44/80 --- 48.382 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 79.85}\n","epoch 45/80 --- 48.336 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 79.75}\n","epoch 46/80 --- 48.301 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 80.27}\n","epoch 47/80 --- 48.197 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 77.41}\n","epoch 48/80 --- 48.199 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 80.21}\n","epoch 49/80 --- 48.337 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 81.17}\n","epoch 50/80 --- 48.191 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 80.42}\n","epoch 51/80 --- 48.212 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 80.45}\n","epoch 52/80 --- 48.224 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 79.97}\n","epoch 53/80 --- 48.209 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 80.46}\n","epoch 54/80 --- 48.021 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 79.85}\n","epoch 55/80 --- 47.835 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 81.41}\n","epoch 56/80 --- 47.816 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 78.93}\n","epoch 57/80 --- 47.889 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 81.44}\n","epoch 58/80 --- 47.907 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 79.6}\n","epoch 59/80 --- 47.950 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 81.04}\n","epoch 60/80 --- 47.788 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 83.48}\n","epoch 61/80 --- 47.835 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 83.47}\n","epoch 62/80 --- 47.949 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 83.55}\n","epoch 63/80 --- 48.288 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 83.58}\n","epoch 64/80 --- 48.204 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 83.55}\n","epoch 65/80 --- 48.296 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 83.52}\n","epoch 66/80 --- 48.161 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 83.57}\n","epoch 67/80 --- 48.228 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 83.57}\n","epoch 68/80 --- 48.295 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 83.5}\n","epoch 69/80 --- 47.771 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 83.52}\n","epoch 70/80 --- 48.026 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 83.53}\n","epoch 71/80 --- 48.360 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 83.83}\n","epoch 72/80 --- 48.602 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 83.81}\n","epoch 73/80 --- 48.539 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 83.45}\n","epoch 74/80 --- 48.401 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 83.65}\n","epoch 75/80 --- 48.388 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 83.53}\n","epoch 76/80 --- 48.449 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 83.59}\n","epoch 77/80 --- 48.603 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 83.81}\n","epoch 78/80 --- 48.406 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 83.65}\n","epoch 79/80 --- 48.427 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 83.8}\n","epoch 80/80 --- 48.353 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 83.67}\n","Total elapsed time : 4045.319 seconds --- \n","Best accuracy was : 83.83\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IrBNmCkEAxwv","colab_type":"code","outputId":"068f9aec-95df-4aae-aa38-1f6416003c52","executionInfo":{"status":"ok","timestamp":1575344464918,"user_tz":-540,"elapsed":3955347,"user":{"displayName":"이찬화","photoUrl":"","userId":"08529154005167969207"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["epochs = 80\n","lambda_ = 0.8\n","gamma_ = 0.1\n","trial_num = 5\n","chseed = 20 # 20 31 55\n","torch.manual_seed(chseed); torch.cuda.manual_seed(chseed)\n","trial_id = myname + \"_\" + str(chseed) +\"_\" + str(batch_size) + \" # \" + str(trial_num)\n","\n","student = 'resnet8'\n","student_model = create_cnn_model(student, dataset, use_cuda=True)\n","\n","train_config = {\n","\t\t'epochs': epochs,\n","\t\t'learning_rate': 0.1,\n","\t\t'momentum': 0.9,\n","\t\t'weight_decay': 0.0001,\n","\t\t'device': 'cuda',\n","\t\t'is_plane': False,\n","\t\t'trial_id': trial_id,\n","\t\t'name': student,\n","    'T_student': 3, #config.get('T_student')\n","\t\t'lambda_student': lambda_, #config.get('lambda_student')\n","\t\t'gamma' : gamma_ # \n","\t}\n","\n","young = ''\n","young_checkpoint = ''\n","# copy and paste\n","\n","if young:\n","    print(\"---------- Loading Young -------\")\n","    young_model = create_cnn_model(young, dataset, use_cuda=True)\n","    young_model = load_checkpoint(young_model, young_checkpoint)\n","    student_trainer = NewTrainManager(student_model, teacher=teacher_model, young = young_model, train_loader=train_loader, test_loader=test_loader, train_config=train_config)\n","    student_trainer.train()\n","else:\n","    print(\"---------- Without Young -------\")\n","    student_trainer = NewTrainManager(student_model, teacher=teacher_model, young = None, train_loader=train_loader, test_loader=test_loader, train_config=train_config)\n","    print(1)\n","    student_trainer.train() "],"execution_count":0,"outputs":[{"output_type":"stream","text":["---------- Without Young -------\n","1\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1946: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n","  warnings.warn(\"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n"],"name":"stderr"},{"output_type":"stream","text":["epoch 1/80 --- 47.350 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 32.85}\n","epoch 2/80 --- 46.948 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 38.13}\n","epoch 3/80 --- 46.935 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 43.16}\n","epoch 4/80 --- 46.887 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 47.93}\n","epoch 5/80 --- 46.849 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 53.52}\n","epoch 6/80 --- 46.888 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 51.46}\n","epoch 7/80 --- 46.930 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 57.45}\n","epoch 8/80 --- 46.895 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 59.17}\n","epoch 9/80 --- 46.911 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 61.53}\n","epoch 10/80 --- 46.959 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 62.89}\n","epoch 11/80 --- 46.952 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 63.74}\n","epoch 12/80 --- 46.899 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 66.23}\n","epoch 13/80 --- 46.935 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 63.09}\n","epoch 14/80 --- 46.954 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 66.41}\n","epoch 15/80 --- 46.884 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 69.32}\n","epoch 16/80 --- 46.780 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 68.11}\n","epoch 17/80 --- 46.824 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 67.42}\n","epoch 18/80 --- 46.883 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 70.09}\n","epoch 19/80 --- 46.950 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 70.01}\n","epoch 20/80 --- 46.946 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 71.45}\n","epoch 21/80 --- 47.040 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 71.14}\n","epoch 22/80 --- 46.925 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 71.46}\n","epoch 23/80 --- 46.900 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 72.94}\n","epoch 24/80 --- 46.932 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 73.61}\n","epoch 25/80 --- 46.946 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 73.53}\n","epoch 26/80 --- 46.926 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 72.51}\n","epoch 27/80 --- 46.946 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 73.24}\n","epoch 28/80 --- 46.917 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 74.2}\n","epoch 29/80 --- 46.913 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 74.49}\n","epoch 30/80 --- 46.952 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 73.96}\n","epoch 31/80 --- 46.957 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 74.68}\n","epoch 32/80 --- 46.989 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 75.28}\n","epoch 33/80 --- 46.925 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 76.04}\n","epoch 34/80 --- 46.951 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 75.22}\n","epoch 35/80 --- 46.916 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 76.43}\n","epoch 36/80 --- 46.990 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 77.24}\n","epoch 37/80 --- 47.060 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 77.46}\n","epoch 38/80 --- 47.000 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 76.46}\n","epoch 39/80 --- 46.933 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 78.33}\n","epoch 40/80 --- 46.950 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 76.35}\n","epoch 41/80 --- 46.931 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 78.32}\n","epoch 42/80 --- 46.933 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 76.5}\n","epoch 43/80 --- 46.940 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 77.28}\n","epoch 44/80 --- 46.952 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 77.48}\n","epoch 45/80 --- 46.918 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 77.42}\n","epoch 46/80 --- 46.937 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 78.61}\n","epoch 47/80 --- 46.927 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 77.56}\n","epoch 48/80 --- 46.893 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 79.48}\n","epoch 49/80 --- 46.919 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 78.45}\n","epoch 50/80 --- 46.955 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 76.47}\n","epoch 51/80 --- 46.966 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 75.32}\n","epoch 52/80 --- 46.911 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 78.79}\n","epoch 53/80 --- 46.864 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 78.34}\n","epoch 54/80 --- 46.935 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 78.81}\n","epoch 55/80 --- 47.155 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 80.02}\n","epoch 56/80 --- 47.300 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 79.28}\n","epoch 57/80 --- 47.430 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 80.63}\n","epoch 58/80 --- 47.258 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 80.13}\n","epoch 59/80 --- 47.277 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 79.73}\n","epoch 60/80 --- 47.372 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 82.44}\n","epoch 61/80 --- 47.285 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 82.44}\n","epoch 62/80 --- 47.266 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 82.05}\n","epoch 63/80 --- 47.287 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 82.53}\n","epoch 64/80 --- 47.321 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 82.35}\n","epoch 65/80 --- 47.278 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 82.34}\n","epoch 66/80 --- 47.318 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 82.38}\n","epoch 67/80 --- 47.204 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 82.41}\n","epoch 68/80 --- 47.174 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 82.37}\n","epoch 69/80 --- 47.253 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 82.41}\n","epoch 70/80 --- 47.171 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 82.47}\n","epoch 71/80 --- 47.169 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 82.57}\n","epoch 72/80 --- 47.189 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 82.71}\n","epoch 73/80 --- 47.192 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 82.64}\n","epoch 74/80 --- 47.202 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 82.6}\n","epoch 75/80 --- 47.059 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 82.55}\n","epoch 76/80 --- 47.187 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 82.71}\n","epoch 77/80 --- 47.191 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 82.41}\n","epoch 78/80 --- 47.164 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 82.39}\n","epoch 79/80 --- 47.029 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 82.69}\n","epoch 80/80 --- 47.040 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 82.65}\n","Total elapsed time : 3954.418 seconds --- \n","Best accuracy was : 82.71\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3J_lceqpAxze","colab_type":"code","outputId":"d215da6b-4d51-4bd5-b17b-cdc00c95e3ab","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["epochs = 80\n","lambda_ = 0.9\n","gamma_ = 0.05\n","trial_num = 6\n","chseed = 20 # 20 31 55\n","torch.manual_seed(chseed); torch.cuda.manual_seed(chseed)\n","trial_id = myname + \"_\" + str(chseed) +\"_\" + str(batch_size) + \" # \" + str(trial_num)\n","\n","student = 'resnet8'\n","student_model = create_cnn_model(student, dataset, use_cuda=True)\n","\n","train_config = {\n","\t\t'epochs': epochs,\n","\t\t'learning_rate': 0.1,\n","\t\t'momentum': 0.9,\n","\t\t'weight_decay': 0.0001,\n","\t\t'device': 'cuda',\n","\t\t'is_plane': False,\n","\t\t'trial_id': trial_id,\n","\t\t'name': student,\n","    'T_student': 3, #config.get('T_student')\n","\t\t'lambda_student': lambda_, #config.get('lambda_student')\n","\t\t'gamma' : gamma_ # \n","\t}\n","\n","young = ''\n","young_checkpoint = ''\n","# copy and paste\n","\n","if young:\n","    print(\"---------- Loading Young -------\")\n","    young_model = create_cnn_model(young, dataset, use_cuda=True)\n","    young_model = load_checkpoint(young_model, young_checkpoint)\n","    student_trainer = NewTrainManager(student_model, teacher=teacher_model, young = young_model, train_loader=train_loader, test_loader=test_loader, train_config=train_config)\n","    student_trainer.train()\n","else:\n","    print(\"---------- Without Young -------\")\n","    student_trainer = NewTrainManager(student_model, teacher=teacher_model, young = None, train_loader=train_loader, test_loader=test_loader, train_config=train_config)\n","    print(1)\n","    student_trainer.train() "],"execution_count":0,"outputs":[{"output_type":"stream","text":["---------- Without Young -------\n","1\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1946: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n","  warnings.warn(\"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n"],"name":"stderr"},{"output_type":"stream","text":["epoch 1/80 --- 46.560 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 30.94}\n","epoch 2/80 --- 46.635 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 37.35}\n","epoch 3/80 --- 46.657 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 40.95}\n","epoch 4/80 --- 46.693 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 44.43}\n","epoch 5/80 --- 46.615 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 48.65}\n","epoch 6/80 --- 46.590 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 49.93}\n","epoch 7/80 --- 46.519 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 52.9}\n","epoch 8/80 --- 46.518 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 60.1}\n","epoch 9/80 --- 46.566 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 61.02}\n","epoch 10/80 --- 46.588 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 61.91}\n","epoch 11/80 --- 46.652 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 61.73}\n","epoch 12/80 --- 46.661 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 64.1}\n","epoch 13/80 --- 46.684 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 64.9}\n","epoch 14/80 --- 46.686 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 64.41}\n","epoch 15/80 --- 46.648 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 65.49}\n","epoch 16/80 --- 46.657 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 65.92}\n","epoch 17/80 --- 46.667 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 66.5}\n","epoch 18/80 --- 46.667 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 69.71}\n","epoch 19/80 --- 46.683 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 68.19}\n","epoch 20/80 --- 46.681 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 68.45}\n","epoch 21/80 --- 46.639 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 69.85}\n","epoch 22/80 --- 46.683 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 68.92}\n","epoch 23/80 --- 46.679 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 70.22}\n","epoch 24/80 --- 46.637 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 72.18}\n","epoch 25/80 --- 46.679 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 71.96}\n","epoch 26/80 --- 46.701 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 71.92}\n","epoch 27/80 --- 46.699 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 72.97}\n","epoch 28/80 --- 46.590 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 73.48}\n","epoch 29/80 --- 46.567 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 73.17}\n","epoch 30/80 --- 46.387 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 72.42}\n","epoch 31/80 --- 46.414 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 72.7}\n","epoch 32/80 --- 46.499 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 75.04}\n","epoch 33/80 --- 46.467 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 73.83}\n","epoch 34/80 --- 46.476 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 75.26}\n","epoch 35/80 --- 46.486 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 76.27}\n","epoch 36/80 --- 46.484 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 76.83}\n","epoch 37/80 --- 46.349 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 77.17}\n","epoch 38/80 --- 46.329 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 76.9}\n","epoch 39/80 --- 46.335 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 75.84}\n","epoch 40/80 --- 46.143 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 74.03}\n","epoch 41/80 --- 46.538 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 75.36}\n","epoch 42/80 --- 46.473 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 77.45}\n","epoch 43/80 --- 46.434 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 76.09}\n","epoch 44/80 --- 46.490 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 76.49}\n","epoch 45/80 --- 46.487 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 78.44}\n","epoch 46/80 --- 46.518 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 77.86}\n","epoch 47/80 --- 46.493 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 76.99}\n","epoch 48/80 --- 46.522 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 78.85}\n","epoch 49/80 --- 46.590 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 79.06}\n","epoch 50/80 --- 46.704 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 77.79}\n","epoch 51/80 --- 46.469 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 78.02}\n","epoch 52/80 --- 46.458 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 79.28}\n","epoch 53/80 --- 46.465 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 79.81}\n","epoch 54/80 --- 46.490 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 79.59}\n","epoch 55/80 --- 46.492 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 80.06}\n","epoch 56/80 --- 46.509 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 78.53}\n","epoch 57/80 --- 46.518 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 80.62}\n","epoch 58/80 --- 46.440 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 78.97}\n","epoch 59/80 --- 46.490 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 79.28}\n","epoch 60/80 --- 46.467 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 81.66}\n","epoch 61/80 --- 46.513 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 81.78}\n","epoch 62/80 --- 46.505 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 81.49}\n","epoch 63/80 --- 46.519 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 81.88}\n","epoch 64/80 --- 46.496 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 81.83}\n","epoch 65/80 --- 46.535 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 81.87}\n","epoch 66/80 --- 46.496 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 81.68}\n","epoch 67/80 --- 46.500 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 81.85}\n","epoch 68/80 --- 46.497 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 81.92}\n","epoch 69/80 --- 46.531 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 81.73}\n","epoch 70/80 --- 46.513 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 81.75}\n","epoch 71/80 --- 46.534 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 81.87}\n","epoch 72/80 --- 46.480 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 81.85}\n","epoch 73/80 --- 46.466 seconds --- \n","{\"metric\": \"resnet8_val_accuracy\", \"value\": 81.68}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"A3kEtldeZmWs","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}